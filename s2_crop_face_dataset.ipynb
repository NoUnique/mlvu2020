{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "s2_crop_face_dataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "220g612iu1lR"
      },
      "source": [
        "## Make your own face dataset (Week 12) - Step 2\n",
        "\n",
        "####**Designed by Joon Son Chung, November 2020**\n",
        "\n",
        "This notebook provides the script to crop face regions from the downloaded dataset and save the faces normalized to the center of the image. This method only leaves the files with only one face detection.\n",
        "Note that the script only considers files with `.jpg` extension.\n",
        "\n",
        "The face detector can be downloaded from [here](http://www.robots.ox.ac.uk/~joon/data/s3fd_facedet.zip).\n",
        "\n",
        "First, connect to Google Drive and extract the face detector.\n",
        "\n",
        "Uncomment the line below and change the path if you have the images on Google Drive.\n",
        "\n",
        "```\n",
        "# orig_path = os.path.join(GDRIVE_HOME,'SNU/Face_Dataset')\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmRyd6HNrv12"
      },
      "source": [
        "from google.colab import drive\n",
        "from zipfile import ZipFile\n",
        "from tqdm import tqdm\n",
        "import os, glob, sys, shutil, time\n",
        "import numpy as np\n",
        "import torch\n",
        "import cv2\n",
        "\n",
        "# mount Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# path of the data directory relative to the home folder of Google Drive\n",
        "GDRIVE_HOME = '/content/drive/My Drive'\n",
        "FOLDER      = 'MLVU/your_dataset'\n",
        "\n",
        "# The following 4 lines are the only parts of the code that you need to change. You can simply run the rest.\n",
        "data_dir        = os.path.join(GDRIVE_HOME,FOLDER) \n",
        "detector_path   = os.path.join(GDRIVE_HOME,'MLVU/s3fd_facedet.zip') # Location of the face detector\n",
        "orig_path       = './original_images' # Location to temporarily store the original images. No need to change this. \n",
        "temp_path       = './cropped_images' # Location to temporarily store your cropped images. No need to change this. \n",
        "\n",
        "assert os.path.exists(detector_path), \"[!] Enter a valid path.\"\n",
        "assert os.path.exists(data_dir), \"[!] Enter a valid path.\"\n",
        "\n",
        "with ZipFile(data_dir+'/original_data.zip', 'r') as zipObj:\n",
        "  zipObj.extractall(orig_path)\n",
        "print('Zip extraction complete')\n",
        "\n",
        "# If you have downloaded the images directly onto Google Drive, uncomment the following line\n",
        "# orig_path = os.path.join(GDRIVE_HOME,'SNU/Face_Dataset')\n",
        "\n",
        "# Copy the detector code and model from the first assignment to the current directory\n",
        "with ZipFile(detector_path, 'r') as zipObj:\n",
        "  zipObj.extractall('detectors')\n",
        "print('Zip extraction complete')\n",
        "\n",
        "files = glob.glob(orig_path+'/*/*.jpg')\n",
        "print(len(files),'original images found.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldN1W0BX_Ufb"
      },
      "source": [
        "Now, load the detector model.  **You do not need to change this section**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RliXhrMEvORL"
      },
      "source": [
        "!pwd\n",
        "sys.path.append('detectors')\n",
        "from detectors import S3FD\n",
        "\n",
        "# Load the face detector (you can ignore this part)\n",
        "DET = S3FD(device='cuda')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qqg0FXYQIp9V"
      },
      "source": [
        "Here, we define the data loader for reading the images. **You do not need to change this section.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mNyyu3P-CqL"
      },
      "source": [
        "class your_dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data_path):\n",
        "\n",
        "        self.data   = glob.glob(data_path+'/*/*.jpg')\n",
        "\n",
        "        print('%d files in the dataset'%len(self.data))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "      fname = self.data[index]\n",
        "      image = cv2.imread(fname)\n",
        "      image_np = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "      return image, image_np, fname\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.data)\n",
        "\n",
        "dataset = your_dataset(orig_path)\n",
        "loader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, num_workers=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1Zm9zicVM5X"
      },
      "source": [
        "We now crop the faces and save them to a temporary folder. This step should take around 10 minutes for 5,000 images. **You do not need to change this section.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbynyGiEVNvx"
      },
      "source": [
        "for data in tqdm(loader):\n",
        "  \n",
        "  image     = data[0][0].numpy()\n",
        "  image_np  = data[1][0].numpy()\n",
        "  fname     = data[2][0]\n",
        "\n",
        "  bboxes = DET.detect_faces(image_np, conf_th=0.9, scales=[0.5])\n",
        "\n",
        "  ## this removes all images with no face detection or two or more face detections\n",
        "  if len(bboxes) == 1:\n",
        "\n",
        "    try:\n",
        "\n",
        "      bsi = 100\n",
        "\n",
        "      sx = int((bboxes[0][0]+bboxes[0][2])/2) + bsi\n",
        "      sy = int((bboxes[0][1]+bboxes[0][3])/2) + bsi\n",
        "      ss = int(max((bboxes[0][3]-bboxes[0][1]),(bboxes[0][2]-bboxes[0][0]))/2)\n",
        "\n",
        "      image = np.pad(image,((bsi,bsi),(bsi,bsi),(0,0)), 'constant', constant_values=(110,110))\n",
        "\n",
        "      face = image[int(sy-ss):int(sy+ss),int(sx-ss):int(sx+ss)]\n",
        "      face = cv2.resize(face,(240,240))\n",
        "\n",
        "      outname = fname.replace(orig_path,temp_path)\n",
        "\n",
        "      if not os.path.exists(os.path.dirname(outname)):\n",
        "        os.makedirs(os.path.dirname(outname))\n",
        "\n",
        "      cv2.imwrite(outname,face)\n",
        "\n",
        "    except:\n",
        "\n",
        "      print('Error on %s'%fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3PRfKSrNCX3"
      },
      "source": [
        "Check the output files. Then zip and save to Google Drive. **You do not need to change this section.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJi53c8ANCu1"
      },
      "source": [
        "output_files = glob.glob(temp_path+'/*/*.jpg')\n",
        "\n",
        "print('%d cropped images found. Now zipping. '%len(output_files))\n",
        "\n",
        "shutil.make_archive(data_dir+'/cropped_data', 'zip', root_dir=temp_path)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}