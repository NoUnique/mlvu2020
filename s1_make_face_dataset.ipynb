{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "s1_make_face_dataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YBh7xiMs3Uv"
      },
      "source": [
        "## Make your own face dataset (Week 12) - Step 1\n",
        "\n",
        "\n",
        "####**Designed by Joon Son Chung, November 2020**\n",
        "\n",
        "This script downloads images from Bing Image Search. At the time of writing, the API is free for up to 1,000 search queries per month.\n",
        "\n",
        "Modify the following parameters, then click `Runtime > Run all`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9p8SoHOBspK8"
      },
      "source": [
        "from google.colab import drive\n",
        "import os, glob, sys, numpy, cv2, random, requests, shutil\n",
        "from requests import exceptions\n",
        "\n",
        "# mount Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# path of the data directory relative to the home folder of Google Drive\n",
        "GDRIVE_HOME = '/content/drive/My Drive'\n",
        "FOLDER      = 'MLVU/your_dataset' # This is the directory where your files will be saved\n",
        "\n",
        "# this is the folder to write to\n",
        "data_dir        = os.path.join(GDRIVE_HOME,FOLDER) \n",
        "temp_path       = './downloaded_images'\n",
        "assert os.path.exists(data_dir)\n",
        "\n",
        "# your Bing API key (Bing Search V7)\n",
        "API_KEY = \"7fbee1b51ba24fa1b08c7e93360a0182\"\n",
        "\n",
        "# keywords to search (names of people)\n",
        "words = ['유재석','강호동',\n",
        "         '박근혜','손흥민',\n",
        "         '추미애','안철수']\n",
        "\n",
        "# number of images per identity\n",
        "max_results = 100\n",
        "\n",
        "print('We are going to search and download images for',len(words),'identities')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nfrq1WWWtcC0"
      },
      "source": [
        "This is the tool for searching and downloading from Bing. **You do not need to change this section.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSIfmvQktcSR"
      },
      "source": [
        "# Adapted from https://www.pyimagesearch.com\n",
        "\n",
        "def search_and_download(term,tgt_dir,API_KEY,MAX_RESULTS=250,GROUP_SIZE=50):\n",
        "\n",
        "  # Saved at tgt_dir/term\n",
        "  save_dir = os.path.join(tgt_dir,term)\n",
        "\n",
        "  # Make directory if missing\n",
        "  if not os.path.exists(save_dir):\n",
        "    print('Creating directory %s'%save_dir)\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "  URL = \"https://api.bing.microsoft.com/v7.0/images/search\"\n",
        "\n",
        "  # when attempting to download images from the web both the Python\n",
        "  # programming language and the requests library have a number of\n",
        "  # exceptions that can be thrown so let's build a list of them now\n",
        "  # so we can filter on them\n",
        "  EXCEPTIONS = set([IOError, FileNotFoundError,\n",
        "    exceptions.RequestException, exceptions.HTTPError,\n",
        "    exceptions.ConnectionError, exceptions.Timeout])\n",
        "\n",
        "  headers = {\"Ocp-Apim-Subscription-Key\" : API_KEY}\n",
        "  params = {\"q\": term, \"offset\": 0, \"count\": GROUP_SIZE}\n",
        "  # make the search\n",
        "  print(\"[INFO] searching Bing API for '{}'\".format(term))\n",
        "  search = requests.get(URL, headers=headers, params=params)\n",
        "  search.raise_for_status()\n",
        "  # grab the results from the search, including the total number of\n",
        "  # estimated results returned by the Bing API\n",
        "  results = search.json()\n",
        "  estNumResults = min(results[\"totalEstimatedMatches\"], MAX_RESULTS)\n",
        "  print(\"[INFO] {} total results for '{}'\".format(estNumResults,\n",
        "    term))\n",
        "  # initialize the total number of images downloaded thus far\n",
        "  total = 0\n",
        "\n",
        "  # loop over the estimated number of results in `GROUP_SIZE` groups\n",
        "  for offset in range(0, estNumResults, GROUP_SIZE):\n",
        "    # update the search parameters using the current offset, then\n",
        "    # make the request to fetch the results\n",
        "    print(\"[INFO] making request for group {}-{} of {}...\".format(\n",
        "      offset, offset + GROUP_SIZE, estNumResults))\n",
        "    params[\"offset\"] = offset\n",
        "    search = requests.get(URL, headers=headers, params=params)\n",
        "    search.raise_for_status()\n",
        "    results = search.json()\n",
        "    print(\"[INFO] saving images for group {}-{} of {}...\".format(\n",
        "      offset, offset + GROUP_SIZE, estNumResults))\n",
        "    # loop over the results\n",
        "    for v in results[\"value\"]:\n",
        "      # try to download the image\n",
        "      try:\n",
        "        # make a request to download the image\n",
        "        print(\"[INFO] fetching: {}\".format(v[\"contentUrl\"]))\n",
        "        r = requests.get(v[\"contentUrl\"], timeout=30)\n",
        "        # build the path to the output image\n",
        "        ext = v[\"contentUrl\"][v[\"contentUrl\"].rfind(\".\"):]\n",
        "        p = os.path.sep.join([save_dir, \"{}{}\".format(\n",
        "          str(total).zfill(8), ext)])\n",
        "        # write the image to disk\n",
        "        f = open(p, \"wb\")\n",
        "        f.write(r.content)\n",
        "        f.close()\n",
        "      # catch any errors that would not unable us to download the\n",
        "      # image\n",
        "      except Exception as e:\n",
        "        # check to see if our exception is in our list of\n",
        "        # exceptions to check for\n",
        "        if type(e) in EXCEPTIONS:\n",
        "          print(\"[INFO] skipping: {}\".format(v[\"contentUrl\"]))\n",
        "          continue\n",
        "        p = ''\n",
        "      # try to load the image from disk\n",
        "      image = cv2.imread(p)\n",
        "      # if the image is `None` then we could not properly load the\n",
        "      # image from disk (so it should be ignored)\n",
        "      if image is None and os.path.exists(p):\n",
        "        print(\"[INFO] deleting: {}\".format(p))\n",
        "        os.remove(p)\n",
        "        continue\n",
        "      # update the counter\n",
        "      total += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQzAZqgVtris"
      },
      "source": [
        "This part executes the download script. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzfask2Fs3Do"
      },
      "source": [
        "for word in words:\n",
        "  ## MAX_RESULTS defines the number of images per search term\n",
        "  search_and_download(word,temp_path,API_KEY,MAX_RESULTS=max_results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOT_uRgl05Zx"
      },
      "source": [
        "Check the output files. Then zip and save to Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuLnKDgs06hA"
      },
      "source": [
        "output_files = glob.glob(temp_path+'/*/*.jpg')\n",
        "\n",
        "print('%d downloaded images found. Now zipping. '%len(output_files))\n",
        "\n",
        "shutil.make_archive(data_dir+'/original_data', 'zip', root_dir=temp_path)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}